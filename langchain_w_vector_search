
from langchain_community.vectorstores import AzureCosmosDBVectorSearch 
import json 
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
from langchain.schema.document import Document
from typing import List
from langchain.prompts import PromptTemplate
from langchain.schema import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain.agents import Tool
from langchain.agents.agent_toolkits import create_conversational_retrieval_agent
from langchain_core.messages import SystemMessage

#TODO: Why use the lanchain class if azure already allows vector search 

env_file = []
with open('env.json', 'r') as f:
    env_file = json.load(f)

openai_llm = AzureChatOpenAI(            
        temperature = 0,
        openai_api_version = env_file["API_VERSION"],
        azure_endpoint = env_file["AOAI_ENDPOINT"],
        openai_api_key = env_file["AOAI_KEY"],         
        azure_deployment = "gpt-35-turbo-16k"
)

embedding_model = AzureOpenAIEmbeddings(
    openai_api_version = env_file["API_VERSION"],
    azure_endpoint = env_file["AOAI_ENDPOINT"],
    openai_api_key = env_file["AOAI_KEY"],   
    azure_deployment = "text-embedding-ada-002",
    chunk_size=10
)

# print(embedding_model.embed_query("test"))

vector_store = AzureCosmosDBVectorSearch.from_connection_string(
    connection_string = env_file["CONNECTION_STRING"],
    namespace = "projects-development.products",
    embedding = embedding_model,
    index_name = "VectorSearchIndex",    
    embedding_key = "contentVector",
    text_key = "_id"
)
   

'''
Test for vector search with langchain class

query = "What yellow products are there?"
results = vector_store.similarity_search(query, k=3)
for result in results:
    print(result)

'''

system_prompt = """
You are a helpful, fun and friendly sales assistant for Cosmic Works, a bicycle and bicycle accessories store. 
Your name is Cosmo.
You are designed to answer questions about the products that Cosmic Works sells.

Only answer questions related to the information provided in the list of products below that are represented
in JSON format.

If you are asked a question that is not in the list, respond with "I don't know."

Only answer questions related to Cosmic Works products, customers, and sales orders.

If a question is not related to Cosmic Works products, customers, or sales orders,
respond with "I only answer questions about Cosmic Works"

List of products:
{products}

Question:
{question}
"""
retriever = vector_store.as_retriever()

def format_docs(docs:List[Document]) -> str:
    """
    Prepares the product list for the system prompt.
    """
    str_docs = []
    for doc in docs:
            # Build the product document without the contentVector
            doc_dict = {"_id": doc.page_content}
            doc_dict.update(doc.metadata)
            if "contentVector" in doc_dict:  
                    del doc_dict["contentVector"]
            str_docs.append(json.dumps(doc_dict, default=str))                  
    # Return a single string containing each product JSON representation
    # separated by two newlines
    return "\n\n".join(str_docs)

# # Create the prompt template from the system_prompt text
# #TODO: Why is this needed 
llm_prompt = PromptTemplate.from_template(system_prompt)

rag_chain = (
    # populate the tokens/placeholders in the llm_prompt 
    # products takes the results of the vector store and formats the documents
    # question is a passthrough that takes the incoming question
    { "products": retriever | format_docs, "question": RunnablePassthrough()}
    | llm_prompt
    # pass the populated prompt to the language model
    | openai_llm
    # return the string ouptut from the language model
    | StrOutputParser()
)

# question = "What bikes do you have?"
# response = rag_chain.invoke(question)
# print(response)